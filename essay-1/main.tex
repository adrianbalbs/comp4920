\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[style=authoryear, backend=biber]{biblatex}

\addbibresource{bibliography.bib} %Import the bibliography file
\DeclareNameAlias{sortname}{family-given}
\renewbibmacro{in:}{}

\setlength{\parskip}{0.8em}

\title{COMP4920 Essay 1}
\author{Adrian Balbalosa, z5397730}
\date{September 2024}

\begin{document}

\maketitle

\section{Introduction}
The notion of Kantian ethics to treat all rational beings as
equal is a strength of this ethical framework. However, the flaws of Kantainism 
begin to show when we begin to justify more complex ethical dilemmas. The 
use of Kantian ethics to design an automated ethics, particularly the creation of
Artificial Moral Agents (AMAs) has provided interesting implications. This essay
argues that Kantian Ethics is an appealing ethical framework to develop an automated 
ethics because of its consistency and fairness, but we must not overlook the lack of 
empathy and issues of accountability. 

\section{An Assessment of Kantian Ethics}
% TODO: Possibly add references here
Kantian Ethics is a deontological ethical theory which places emphasis on duty and
moral principles over consequences. Central to this framework is the notion of the
"categorical imperative". There are a few formulations of it, one which states that one should act according to the maxims which
can be universally applied. Another formulation of this is that individuals should treat
others as an ends, not just a means to an end. Kantian Ethics prioritises rationality and
personal freedoms, and argues that ethical actions should arise from a sense of duty and
adhering to moral law, rather than from emotional or situational considerations.

A notable strength of Kantian Ethics is that it places emphasis on respect
for the individual, grounded in the ideal that humans as rational agents possess intrinsic worth. Kant 
argues that because we have the capacity for rational behaviour and can act independently beyond our
impulses, we must always be treated as an ends in ourselves, never merely as a means \parencite[p. 77]{bennet2015}. 
This ensures the protection of human dignity and rights, such that individuals are valued for their
capacity for rational thought.

However, Kantian Ethics faces significant challenge when duties conflict, as it provides
no clear guidance for how to resolve those dilemmas. A classical example used by
critics of Kantianism is the "murderer at the door" scenario, where the morally correct response is
to tell the truth, even though lying would save the life of someone \parencite[p. 81]{bennet2015}. In this case,
respecting the autonomy of the murderer by telling the truth appears contradictory in nature, as it 
disregards the potential harm to another individual. This highlights a limitation of Kant's ethical system,
as it struggles to navigate complex moral situations where duties may clash.

\section{The Applicability of Kantian Ethics to Automated Ethics}

An opportunity of the application of Kantian ethics to automated ethics is its potential for ethical consistency and 
fairness. \textcite[p. 16]{singh2022} argues that "Kantian ethics is more natural to formalise" compared
to other ethical theories, as "the Formula of Universal Law evaluates the form and structure of an agent's
maxim" and requires less knowledge about the "state of affairs" or "moral character". This argument is 
further solidified through their implementation of an AMA that can successfully evaluate certain
ethical scenarios, like the nature of joking and lying \parencite[6--7]{singh2022}. Since Kantian
ethics is a rule-based system which focuses on upholding clear and universal rules, it has been shown to
mix well with such automated systems by being computationally tractable. As a result of this, such 
automated systems are able to remain consistent when following a set of predefined rules perscribed by
Kantian ethics.

A risk of the application of Kantian ethics to automated ethics is that artificial moral agents lack
genuine autonomy or consciousness. Kant states that transcendental freedom is "fundamental requirement of morality"
\parencite[p. 142]{mannananth2021}. That is in order to be considered a moral agent, a rational being should 
have the capability of acting autonomously rather than being controlled from external influences. \textcite[p. 149]{mannananth2021}
argue that "AI Systems are deterministic models of agency that do not exceed its initial programming". Since AMAs are
only able to act within the bounds of their programming, AMAs do not possess any consciousness or autonomy. The actions
of AMAs are mechanically driven, rather than driven by a sense of rationality. The implications of this are that 
Kantian machines will be devoid of any moral intuition or empathy, which is crucial to respecting the dignity of
a rational being.

Another risk that is present is that an over-reliance on artificial moral agents would have the potential to diminish human engagement
with moral responsibility. \textcite[p. 146]{mannananth2021} claim that "AI's moral deeds are not generated from
the 'freedom of will' and the sense of 'duty' itself", but are simply a result of the programmer's instructions. 
This raises concerns about who is truly responsible for the outcomes of ethical decisions that are made by AMAs. 
Despite being programmed to follow ethical guidelines, the actions behind them lack moral reasoning, as they are 
incapable of understanding the principles behind the decisions they make. Thus, the nature of who takes responsibility
when an ethical failure occurs becomes ambiguous.

\textcite[p. 148]{mannananth2021} further argue that an AI agent "works according to hypothetical rules" rather than 
the categorical imperative. This means they do not act out of a sense of duty, but instead follow a set of conditional
rules established by humans. This raises the issue that AMAs are incapable of comprehending the universal principles
which govern human responsibility. Thus, an over-reliance on these systems will risk diminishing human engagement with moral
accountability. This could lead individuals to trust these automated agents to make such moral decisions, which
absolves an individual of their responsibility to reflect on the ethical implications of their own actions.


\section{Conclusion}
While Katian ethics has shown to be an ethical theory which upholds human dignity and equality,
it fails in more complex situations where maxims may clash against each other. The application
of Kantian ethics to automated ethics presents some interesting opportunities. One of them 
being that Kantian ethics is generally simpler to automate, as the categorical imperative provides
an algorithmic process for making ethical judgements. We must however consider that AMAs 
lack the genuineness of a rational being as a result of a lack of autonomy, and that we must
be careful to not over-rely on them for guidance.

\printbibliography[title={References}]
\end{document}
